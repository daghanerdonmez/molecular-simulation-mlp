{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "import os, glob, numpy as np, torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# CONFIG\n",
    "# ---------------------------------------------------------------------\n",
    "DATA_ROOT       = \"../output-processing/\"   # <-- change if needed\n",
    "MAX_PIPES       = 100\n",
    "MAX_RECEIVERS   = 150\n",
    "PIPE_OH_DIM     = MAX_PIPES          # oneâ€‘hot length\n",
    "PIPE_FEAT_DIM   = PIPE_OH_DIM*2 + 3  # (self OH) + (parent OH) + length,radius,numRecv\n",
    "RECV_FEAT_DIM   = PIPE_OH_DIM + 10   # (pipe OH) + r,z,rad + 7 stats\n",
    "GLOBAL_DIM      = 2                  # diffusion, flow\n",
    "INPUT_DIM       = GLOBAL_DIM + MAX_PIPES*PIPE_FEAT_DIM + MAX_RECEIVERS*RECV_FEAT_DIM\n",
    "TARGET_DIM      = 3                  # pipe_id (normalised), r, z\n",
    "DEVICE          = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "EPOCHS          = 50\n",
    "BATCH_SIZE      = 16\n",
    "LR              = 3e-4\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(index: int, length: int=MAX_PIPES):\n",
    "    vec = np.zeros(length, dtype=np.float32)\n",
    "    if 0 <= index < length:\n",
    "        vec[index] = 1.0\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolSimDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.samples = sorted(glob.glob(os.path.join(root_dir, \"*\")))\n",
    "    def __len__(self):  return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sim_dir     = self.samples[idx]\n",
    "\n",
    "        # -------- global ------------------------------------------------\n",
    "        diffusion, flow = np.loadtxt(os.path.join(sim_dir, \"meta.txt\"), dtype=np.float32)\n",
    "\n",
    "        # -------- pipes -------------------------------------------------\n",
    "        pipes_raw  = np.loadtxt(os.path.join(sim_dir, \"pipes.txt\"), dtype=np.float32, ndmin=2)\n",
    "        pipe_mat   = np.zeros((MAX_PIPES, PIPE_FEAT_DIM), dtype=np.float32)\n",
    "\n",
    "        for row in pipes_raw[:MAX_PIPES]:\n",
    "            p_id, parent_id, length, radius, nrecv = row\n",
    "            p_id, parent_id, nrecv = map(int, (p_id, parent_id, nrecv))\n",
    "            vec  = np.concatenate([\n",
    "                one_hot(p_id),                # self ID\n",
    "                one_hot(parent_id)            # parent ID  (parent_id==-1 gives zeros)\n",
    "                if parent_id>=0 else np.zeros(PIPE_OH_DIM, np.float32),\n",
    "                np.array([length, radius, nrecv], np.float32)\n",
    "            ])\n",
    "            pipe_mat[p_id] = vec\n",
    "\n",
    "        # -------- receivers --------------------------------------------\n",
    "        recv_mat  = np.zeros((MAX_RECEIVERS, RECV_FEAT_DIM), dtype=np.float32)\n",
    "        rec_path  = os.path.join(sim_dir, \"receivers.txt\")\n",
    "        if os.path.getsize(rec_path) > 0:    # receivers.txt might be empty\n",
    "            recv_raw  = np.loadtxt(rec_path, dtype=np.float32, ndmin=2)\n",
    "            for i, row in enumerate(recv_raw[:MAX_RECEIVERS]):\n",
    "                (p_id, r, z, rad,\n",
    "                 first_t, max_val, max_t,\n",
    "                 total, mean, std, skew) = row\n",
    "                p_id = int(p_id)\n",
    "                vec  = np.concatenate([\n",
    "                    one_hot(p_id),                        # pipe identity\n",
    "                    np.array([r, z, rad,\n",
    "                              first_t, max_val, max_t,\n",
    "                              total, mean, std, skew], np.float32)\n",
    "                ])\n",
    "                recv_mat[i] = vec\n",
    "\n",
    "        # -------- target -----------------------------------------------\n",
    "        t_pipe, t_r, t_z = np.loadtxt(os.path.join(sim_dir,\"target.txt\"), dtype=np.float32)\n",
    "        target           = np.array([t_pipe/MAX_PIPES, t_r, t_z], np.float32)  # normalise pipe id\n",
    "\n",
    "        # -------- stack -------------------------------------------------\n",
    "        x = np.concatenate([\n",
    "            np.array([diffusion, flow], np.float32),\n",
    "            pipe_mat.flatten(),\n",
    "            recv_mat.flatten()\n",
    "        ])\n",
    "        return torch.tensor(x), torch.tensor(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# MODEL\n",
    "# ---------------------------------------------------------------------\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim=INPUT_DIM, out_dim=TARGET_DIM):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, out_dim)\n",
    "        )\n",
    "    def forward(self, x):  return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = []\n",
    "loss_val = []\n",
    "\n",
    "def train():\n",
    "    train_dataset = MolSimDataset(os.path.join(DATA_ROOT, \"train-data\"))\n",
    "    val_dataset   = MolSimDataset(os.path.join(DATA_ROOT, \"validation-data\"))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    model   = MLP().to(DEVICE)\n",
    "    opt     = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    print(f\"Training: {len(train_dataset)} samples  |  Validation: {len(val_dataset)} samples\\n\")\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        start_time = time.time()\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch:02d}\", unit=\"batch\", ncols=100)\n",
    "\n",
    "        for x, y in loop:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            batch_loss = loss.item()\n",
    "            train_loss += batch_loss * x.size(0)\n",
    "            loop.set_postfix(train_loss=f\"{batch_loss:.4f}\")\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_dataset)\n",
    "        loss_train.append(avg_train_loss)\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "                pred = model(x)\n",
    "                loss = loss_fn(pred, y)\n",
    "                val_loss += loss.item() * x.size(0)\n",
    "        avg_val_loss = val_loss / len(val_dataset)\n",
    "        loss_val.append(avg_val_loss)\n",
    "    \n",
    "        print(f\"Epoch {epoch:02d} completed | train MSE: {avg_train_loss:.6f} | val MSE: {avg_val_loss:.6f} | time: {elapsed:.2f}s\")\n",
    "\n",
    "    print(\"Done training!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw graph of the training and validation loss\n",
    "plt.plot(loss_train, label=\"train\")\n",
    "plt.plot(loss_val, label=\"val\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
